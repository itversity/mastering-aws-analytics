{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with AWS IAM Identity-based Policies\n",
    "\n",
    "Let us understand [AWS IAM Identity-based Policies](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html#policies_id-based). We will be focusing on Predefined policies for now.\n",
    "* Permissions are assigned to policies using JSON Syntax.\n",
    "* Policies are typically attached to either group or role. It is also possible to attach policies directly to users.\n",
    "* **Users, groups, and roles in AWS** are also known as **AWS IAM identities**.\n",
    "* We can attach more than one policy to an AWS IAM identity.\n",
    "* We have predefined policies which we can leverage and also we can define custom policies.\n",
    "* Let us review the following policies to understand how permissions on services are typically defined.\n",
    "    * **AmazonS3FullAccess**\n",
    "    * **AmazonS3ReadOnlyAccess**\n",
    "* Here are the key terms which you should be familiar with related to policies.\n",
    "    * **Effect** - This is where you typically define Allow or Deny\n",
    "    * **Action** - This is where you typically define the type of actions that can be performed\n",
    "    * **Resource** - We can control the permissions over the resources that are related to the Effect.\n",
    "* For example:\n",
    "    * Effect - **s3 (service)**\n",
    "    * Action - **Get, List, Put, Delete**, etc.\n",
    "    * Resource - **Buckets or objects within the bucket we have created**.\n",
    "* Let us perform a few tasks related to Identity-based Policies.\n",
    "    * Create a new user **itvsupport1** with only programmatic access.\n",
    "    * Configure AWS CLI with profile **itvsupport1**.\n",
    "    * Attach **AmazonS3ReadOnlyAccess** to **itvsupport1**.\n",
    "    * Make sure a bucket is created using AWS Web Console by logging in as admin or root user. I will be creating a bucket by the name **dg-retail**. If you already have such a bucket, you can directly copy files into S3.\n",
    "    * Try running this command to copy files into the bucket.\n",
    "```shell\n",
    "aws s3 cp ~/Research/data/retail_db s3://dg-retail1/retail_db/ \\\n",
    "    --recursive \\\n",
    "    --exclude \"*.sql\" \\\n",
    "    --exclude \"README.md\" \\\n",
    "    --profile itvsupport1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
